{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dc0e8c76-5a51-4879-a96d-f8dd90622458",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Fourth Book Blog\"\n",
    "description: \"Updating my analysis on my book on AI\"\n",
    "author: \"Emily\"\n",
    "date: \"11/9/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Learning\n",
    "  - Book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd976152-967c-4bc5-9f0b-899eca9291c1",
   "metadata": {},
   "source": [
    "# Update as of Nov. 9\n",
    "As of November 9, I have read 230 pages of *Unmasking AI*. In my opinion, much of what she covers in these pages builds on themes she introduced earlier in the book. She continues to explore the struggles of convincing people about the necessity of algorithmic justice and raising awareness about the “coded gaze”—the ways in which bias can be embedded in technology. She talks about the struggles in convincing people about the need for algorithmic justice and the awareness for the coded gaze. However, she does bring a new motif in this part of the book: women of color. She discusses how women of color—her ancestors, famous advocates like Sojourner Truth, scholars like Dr. Moya—have influenced her work and journey. By centering these figures, she empahsizes contributions of women of color in technology and activism while simultaneously highlighting the need for algorithmic justice.\n",
    "\n",
    "I also like how she sprinkles lines from poem throughout this part. Some lines include: *\"In her eyes, I see my mother's poise/In her face, I glimpse my auntie's grace\"* or *\"No label is worthy of our beauty.\"* I think these lines serve to humanize her reflections and connect her technical discussions of artificial intelligence to lived experiences, family histories, and cultural inheritance. They really made the reading feel intimate and grounded, and her work all the more visceral to me, reminding me that algorithmic justice is a matter that shapes real lives.\n",
    "\n",
    "Overall, this part of the book balances technical critique with personal storytelling.\n",
    "\n",
    "# Questions and Answers\n",
    "1) **How does the author's personal experience shape the way she frames the problem of bias in AI?**\n",
    "The author's personal experience is actually very central to her framing of AI bias. By drawing on her family history and her ancestry—especially women—and the epxeriences of women of color who came before her, she situates algorithmic bias as one with tangible social consequences. Her reflections on mentorship and the coded gaze demonstrate how lived experiences inform her understanding of how bias manifests in artificial intelligence.\n",
    "2) **Are there any examples in this section where racial or gender bias in AI had real-world consequences? How are these illustrated?**\n",
    "While she does not focus on a single high-profile case, she emphasizes patterns where AI reproduces systemic inequalities—for example, facial recognition technology that fails to accurately identify women of color. These illustrations are often paired with narratives about advocacy and the historical invisibility of marginalized groups.\n",
    "3) **What patterns or repeated arguments do you notice in the author's approach? Do they strengthen or weaken her overall message?**\n",
    "A repeated argument throughout this section is the interplay between technical systems and social context. She frequently connects historical and contemporary experiences of women of color to the design and impact of algorithms. This pattern strengthens her overall message by consistently reminding readers that AI operates within societal structures, not in isolation.\n",
    "4) **How does the author balance technical explanations with accessibility for a general audience?**\n",
    "The author balances tehnical and accessible writing by interweaving concrete examples, historical narratives, and poety with technical discussions. She avoids heavy technical jargon to connect to everyday experiences. Also, the inclusion of personal stories and reflections ensures that even readers without a tehnical background can understand why AI bias matters.\n",
    "5) **Are there moments in this section where the author begins to suggest potential solutions or interventions? How convincing are they?**\n",
    "Yes, the author begins to hint at potential interventions by emphasizing mentorship, advocacy, and community-led approaches to AI development. She also stresses the importance of diversifying the teams who create algorithms. However, the interventions are still presented in broad strokes rather than detailed technical strategies.\n",
    "\n",
    "# More Questions\n",
    "1) Are there new personal stories or anecdotes introduced? How do they help illustrate her arguments about bias?\n",
    "2) Does the author reflect on her own assumptions or biases in this part? How does that influence your reading?\n",
    "3) How does she address counterarguments or criticisms of her work?\n",
    "4) What patterns in reasoning or argumentation does the author repeat in this section? Are they effective?\n",
    "\n",
    "![](book.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471ec644-7827-44a2-a559-85cb6c07dc9c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
