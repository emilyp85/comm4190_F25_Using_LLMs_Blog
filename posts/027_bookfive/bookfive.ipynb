{
 "cells": [
  {
   "cell_type": "raw",
   "id": "36094b7b-6310-4fb9-9929-1ee258e5c09c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Fifth Book Blog\"\n",
    "description: \"Updating my analysis on my book on AI\"\n",
    "author: \"Emily\"\n",
    "date: \"11/13/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Learning\n",
    "  - Book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd1595-5854-4c03-9345-b46345899d59",
   "metadata": {},
   "source": [
    "# Update as of Nov. 13\n",
    "I have read up to page 264 as of November 13. Like what I said in my last blog post about the book, she continues to build upon the themes that she mentions earlier butalso introduces new ones: beauty and erasure of credibility through the persective of a woman of color. Dr. Joy Buolamwini discusses how beauty is a factor in the algorithmic bias: \"The images and videos in the campaign represented what was captured without post-production blemish-reducing techniques\" (263). It is crazy to think that a blemish — a wrongly-placed pimple or a mole — can be the reason why an artificial intelligence model misidentifies someone. This also speaks to how women and girls are boiled down to just their beauty. Dr. Buolamwini also explains how her credibility as a researcher was erased and her research was never credited when big media hosts like Anderson Cooper went on air to explain artificial intelligence and algorithmic bias. She and her work were never mentioned and Cooper went on to explain the bias incorrectly, which frustrated Dr. Buolamwini. She explores those feelings in this part of the book.\n",
    "\n",
    "![](book.jpg)\n",
    "\n",
    "# Questions and Answers\n",
    "1) **Are there new personal stories or anecdotes introduced? How do they help illustrate her arguments about bias?**\n",
    "There are definitely new stories or anecdotes she introduces, the story about Anderson Cooper for one. Dr. Buolamwini recounts how major media figures and outlets discussed her research on algorithmic bias without acknowledging her work or giving her credit. This personal story highlights how the voices and contributions of women of color — especially Black women — are often erased or minimized when they are not sports or entertainment figures, even when they are central to the issue being discussed. It also reinforces her broader argument about systemic bias not only in algorithms but also in the media and academic/scholarly recognition.\n",
    "\n",
    "3) **Does the author reflect on her own assumptions or biases in this part? How does that influence your reading?**\n",
    "Yes, Dr. Buolamwini reflects on her own position as both a researcher and a Black woman navigating predominantly white and male spaces in technology. She recognizes how her personal experiences shape the lens through which she views algorithmic bias. This self-awareness makes her arguments feel more authentic and real.\n",
    "\n",
    "4) **How does she address counterarguments or criticisms of her work?**\n",
    "Dr. Buolamwini addresses criticisms indirectly by emphasizing transparency and the rigor of her research. She shows that her ifndings are not based on speculation or emotion but on measureable data about algorithmic errors and misidentifications. By describing how her work was misrepresented by media figures like Anderson Cooper, she demonstrates how misinformation and oversimplification often distort nuanced research—and that oversimplification is an form of misinformation.\n",
    "\n",
    "5) **What patterns in reasoning or argumentation does the author repeat in this section? Are they effective?**\n",
    "She continues to use a pattern of pairing personal narrative with broader social critique. She begins with an anecdote from her own experience, then connects it to systemic issues such as a sexism, racism, and the biased embedded in technology and the media. This pattern, I would say, is effective because it humanizes abstract concepts like \"algorithmic bias\" which allows readers to grasp their real-world consequences.\n",
    "\n",
    "# More Questions\n",
    "1) What does she suggest about the relationship between beauty standards and algorithmic accuracy?\n",
    "2) How does she use the idea of visibility vs. erasure—both in terms of race and credibility—as a recurring theme?\n",
    "3) How does she illustrate the dangers of assuming technology is “neutral”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a2e09-9b43-4bba-a7da-4a996144d3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
