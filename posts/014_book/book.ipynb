{
 "cells": [
  {
   "cell_type": "raw",
   "id": "05aab596-0069-40ad-8b8a-925a8e3356af",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Book Update\"\n",
    "description: \"Update on what I have read so far\"\n",
    "author: \"Emily\"\n",
    "date: \"10/15/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Learning\n",
    "  - Book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290c5cc-1267-44f1-8ddf-4d55a7174f15",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "![](book.jpg)\n",
    "\n",
    "I am reading *Unmasking AI* by Dr. Joy Buolamwini. [*Unmasking AI*](https://www.amazon.com/Unmasking-AI-Mission-Protect-Machines/dp/B0C3MXLMGQ/ref=sr_1_1?dib=eyJ2IjoiMSJ9.FWcb-XOUEaLMGqX_D5ZDT17952qIgDHb6h0ZueYzg0zC77och9YZYSvEsZrdAK3DeI4zlHR2Z6possHuaOIL5tsiByjF-Ofsp3ujEE2a_MdjOKCyelk-rDWo0Ro3WjPtkd7c8W62LzhBsoTrBPau1wuwa3cPlk3od4WNUkX-09e6TqaV2YFS6z67dvb8LrQyVgoW2MqcOMblW3K3cEKHBgGHZm8Q0SMWYGkEn7Alglw.7Xw_YtOL6naW1rRoupqlPxQfPPl8oLyXWYIJVUDk4mI&dib_tag=se&hvadid=676936604346&hvdev=c&hvexpln=0&hvlocphy=9007284&hvnetw=g&hvocijid=11283600651535000288--&hvqmt=e&hvrand=11283600651535000288&hvtargid=kwd-2013653229083&hydadcr=22196_13517546&keywords=unmasking+ai&mcid=4f40aee169af32c38b936e2980df5790&qid=1760477693&sr=8-1) is about a woman's journey in learning about the intersectionality between race/racism and artificial intelligence. This is the summary I found on Amazon.\n",
    "\n",
    ">To most of us, it seems like recent developments in artificial intelligence emerged out of nowhere to pose unprecedented threats to humankind. But to Dr. Joy Buolamwini, who has been at the forefront of AI research, this moment has been a long time in the making.\n",
    "After tinkering with robotics as a high school student in Memphis and then developing mobile apps in Zambia as a Fulbright fellow, Buolamwini followed her lifelong passion for computer science, engineering, and art to MIT in 2015. As a graduate student at the “Future Factory,” she did groundbreaking research that exposed widespread racial and gender bias in AI services from tech giants across the world.\n",
    "Unmasking AI goes beyond the headlines about existential risks produced by Big Tech. It is the remarkable story of how Buolamwini uncovered what she calls “the coded gaze”—the evidence of encoded discrimination and exclusion in tech products—and how she galvanized the movement to prevent AI harms by founding the Algorithmic Justice League. Applying an intersectional lens to both the tech industry and the research sector, she shows how racism, sexism, colorism, and ableism can overlap and render broad swaths of humanity “excoded” and therefore vulnerable in a world rapidly adopting AI tools. Computers, she reminds us, are reflections of both the aspirations and the limitations of the people who create them.\n",
    "Encouraging experts and non-experts alike to join this fight, Buolamwini writes, “The rising frontier for civil rights will require algorithmic justice. AI should be for the people and by the people, not just the privileged few.”\n",
    "\n",
    "# Update as of Oct. 15\n",
    "I am almost halfway done with the book. So far, I have learned that Dr. Joy Buolamwini is deeply passionate about advocating for racial awareness and equity in the development of artificial intelligence. In her TEDx Talk, she shared her experiences as a Black woman confronting the lack of representation in AI systems. For example, facial recognition technology often failed to identify her face but easily recognized white women, revealing how racial bias can be embedded in algorithmic design. Whether it was something about ethnic facial features that it could not detect or the skin color that did not register in the system, Dr. Joy Buolamwini started to talk to her mentors, friends, and strangers about the necessity of racial representation. She works with MIT on her research.\n",
    "\n",
    "# Takeaway\n",
    "Reading about her work helped me understand why race is such a critical factor in AI ethics. Consider self-driving cars, for instance—if an AI system cannot recognize a Black woman as a human being to avoid, the consequences could be catastrophic, leading to preventable accidents and loss of life. It is shameful to admit, but I never considered race to be a factor in the process of creating artificial intelligence; I always assumed that since all humans share the same basic features—eyes, noses, mouths, and ears—AI should be able to recognize anyone equally. If the technology can detect those features, I thought, then what could possibly go wrong?\n",
    "\n",
    "However, reading more about Unmasking AI completely shifted my perspective. I began to realize that the issue is not with human features themselves, but with how AI systems are trained—on biased datasets that often underrepresent people of color. These systems “learn” what a face looks like based on the images they are given, and if those images overwhelmingly depict white individuals, then AI’s understanding of “a human face” becomes racially skewed. Dr. Buolamwini’s research exposed the dangerous reality that technology, often perceived as objective and neutral, can actually reinforce inequality if the people building it ignore racial diversity. This realization made me more aware of how easily bias can hide behind the façade of innovation, and how vital it is for future developers and policymakers to prioritize inclusivity from the very start.\n",
    "\n",
    "In a twisted way, artificial intelligence is a pretty accurate representation of society. Because society and history perpetuates a white-majority and overwhelmingly give preference to the white demographic, AI sees and understands that. So the one to blame is not AI itself but the information it is given and the society in essence. \n",
    "\n",
    "# In Conclusion\n",
    "\n",
    "I am looking forward to how Dr. Joy Buolamwini will continue to walk down this road on advocating for racial representation and what she will do. I want to see what particular areas — whether in deepfakes or in health research or anything else — she will decide to focus on. Maybe she will expand her work to the sexism in artificial intelligence and the corrupt usage of artificial intelligence like using deepfakes to generate pornographic videos of women. Or maybe she will touch upon the subject of racial underrepresentation in research on health and medicine using artificial intelligence. \n",
    "\n",
    "I am looking forward to seeing how her work will be applied to other works in the future, and who or what she will inspire.\n",
    "\n",
    "# Questions I have\n",
    "1) How can AI developers practically ensure that their training datasets are diverse and representative of all racial and ethnic groups?\n",
    "2) How does Dr. Buolamwini approach intersectionality in AI beyond race—does she consider age, disability, or socioeconomic status in her research?\n",
    "3) Will her future work tackle the ethical challenges posed by emerging AI technologies like deepfakes, predictive policing, or AI-driven health diagnostics?\n",
    "4) Could AI ever be completely unbiased, or will it always reflect the society that trains it?\n",
    "5) How does Dr. Buolamwini respond to critics who argue that focusing on bias slows technological progress?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33a7b3-5422-4829-ba4d-429ad1579287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
