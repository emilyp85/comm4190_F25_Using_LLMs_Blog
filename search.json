[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Emily Park",
    "section": "",
    "text": "This blog is about my explorations and experiments with language models."
  },
  {
    "objectID": "posts/009_outfits/outfits.html",
    "href": "posts/009_outfits/outfits.html",
    "title": "Making an Outfit",
    "section": "",
    "text": "The other day, I decided to test whether ChatGPT could style me an outfit. I thought it would be a fun experiment—why not let AI play personal stylist for once? My vibe lately has been minimalist, cute, and a little trendy, so I figured it couldn’t be too hard.\n\nThe Prompt\nI asked ChatGPT to find me an outfit I could wear. This was the prompt: “Can you generate an outfit for me to wear knowing my styling preferences?”\nSeems straightforward, right? Just give me a head-to-toe look and I’ll be on my way.\nInstead, this was its response:\nI can definitely help with that! To style an outfit for you, I’ll need a little more detail first:\n\nWhat’s the occasion? (e.g., casual day out, class, going out at night, professional, formal, etc.)\n\nDo you have any styling preferences you’d like me to keep in mind? (e.g., minimalist, trendy, classic, chic, streetwear, bold colors, neutral tones).\n\nAny weather or season I should account for?\n\nOnce I know these, I can build a head-to-toe outfit recommendation (clothes, shoes, accessories), and I can even generate a visual mock-up if you’d like.\n\nWant me to put together a test outfit for, say, a casual day on campus?\nIn other words: not an outfit, just… questions. Basically, my “personal stylist” decided it wanted to interview me before doing its job.\nSo I gave it specifics: a casual day for class, minimalist but cute and trendy, and weather in the 70s.\nI was expecting something similar to these outfits I found off of Pinterest. \n\nAnything along the line of casual, minimal, and trendy. And the result?\n\nI felt disappointed that it kept its response generally broad; I was looking for something more specific—a vision that I can execute!\n\n\nWhy This Was a Miss\nWhat I learned is that ChatGPT doesn’t really “see” fashion the way humans do. Style isn’t just about matching weather to clothes. Pinterest or TikTok can deliver that instantly, while ChatGPT still feels like it’s reading from a fashion magazine.\nTo be fair, I might not have been specific enough in my wording. Maybe if I asked, “What should I wear to class on a 70-degree day if I like minimalist looks and trendy sneakers?” the result would’ve been better. But that kind of defeats the fun—I wanted creativity, not a Q&A session.\n\n\nIf I Actually Wore This\nI tried to imagine showing up to class in ChatGPT’s idea of an outfit. I’d probably look like an NPC in a college campus video game—just generically dressed to “blend in.” Nothing offensive, but nothing that I would like to wear—that I would feel comfortable in.\n\n\nFinal Thoughts\nChatGPT lacks creativity, like demonstrated by many of my prior blog posts. It keeps asking me questions when in reality I want it to be more decisive and creative."
  },
  {
    "objectID": "posts/008_children_book/children_book.html",
    "href": "posts/008_children_book/children_book.html",
    "title": "Children Book with ChatGPT",
    "section": "",
    "text": "Prompt\nI asked ChatGPT this prompt:\nCan you make a short children book with illustrations?\nChatGPT answered like this:\nAbsolutely! I can create a short children’s book for you, complete with simple illustrations. To start, could you tell me:\n1) The age range you’d like it for (e.g., toddlers, early readers, 6–8 years old).\n2) The theme or lesson you’d like (e.g., friendship, kindness, adventure, trying new foods).\n3) If you’d like it to feature a specific character (like an animal, child, or magical creature).\n\nThen I can draft the story and generate illustrations for each page so it feels like a real picture book.\nDo you want me to surprise you with the theme, or would you like to choose?\nI answered:\ntoddlers\ntrying new foods\nanimals\nFrom there, ChatGPT drafted a short story called Benny Bunny’s Tasty Adventure. It followed a bunny who loved carrots but slowly discovered new foods—cheese, berries, and lettuce—through the encouragement of his animal friends. The text was simple, rhythmic, and age-appropriate for toddlers.\nChatGPT also described illustration ideas for each page (e.g., a bunny peeking into a picnic basket, a parrot holding berries). This was helpful in imagining how the book might look.\nFinally, I asked if it could actually generate the illustrations. ChatGPT tried twice, but each time the image generation failed with an error.\n\n\nReflection\nI liked how ChatGPT broke down the process before jumping in—it felt like a real collaboration. The story itself was charming and fit the toddler age group well. The illustration prompts were clear and could easily guide an artist.\nThe main limitation was in the illustration generation: the system couldn’t deliver consistent images yet. Still, it showed the potential for AI to draft both text and visual concepts for a children’s book in just minutes.\n\n\nNext Steps\nIf I were to expand this experiment, I’d: * Ask for the story in rhyming verse to make it more musical for toddlers. * Request illustrations in a specific style (e.g., watercolor, collage, crayon doodles) to keep them consistent. * Explore ways to combine text and illustrations into a printable storybook layout. * Add interactive prompts for toddlers (“Point to the red berry,” “Count the carrots”). I asked ChatGPT to do so.\n\n\nRhyming Verses\nThis is what ChatGPT came up with:\nBenny Bunny’s Tasty Adventure\n\nPage 1\nText:\nBenny Bunny munched all day,\nCarrots, carrots—hip hooray!\nBut one bright morning, Benny knew,\nHe wanted to try something new.\nIllustration idea: A cheerful bunny holding a carrot, surrounded by a big sunny field.\n\nPage 2\nText:\nSqueaky Mouse said, “Come and see!\nCheese is soft and yummy to me.”\nBenny nibbled, took a bite,\n“Mmm,” he smiled, “this tastes just right!”\nIllustration idea: A tiny mouse offering a wedge of cheese to Benny on a picnic blanket.\n\nPage 3\nText:\nPolly Parrot flapped her wing,\n“Berries are my favorite thing!”\nBenny tried one, juicy-sweet,\n“Oh,” he laughed, “what a tasty treat!”\nIllustration idea: A bright parrot perched on a tree, dropping red berries into Benny’s paws.\n\nPage 4\nText:\nTimmy Turtle crunched with glee,\n“Lettuce leaves are good for me!”\nBenny munched a leafy snack,\n“Crunch, crunch, crunch—I’ll come back!”\nIllustration idea: A turtle holding a green leaf, smiling as Benny chews beside him.\n\nPage 5\nText:\nCheese and berries, lettuce too,\nSo many foods for Benny to chew!\nCarrots are yummy, but now he knows,\nTrying new foods helps Benny grow!\nIllustration idea: All the animals together, sharing food at a sunny picnic. Benny stands proudly with his carrot in one paw and a berry in the other.\n\nI really wanted an illustration to go with this story so I asked, again, if ChatGPT can generate a book cover that goes with the children’s book, in watercolor style. Unfortunately, ChatGPT ran into an error.\n\n\nReflection\nThis tells me that ChatGPT might have trouble being creative and analyzing a storyline plot to create a graphic. This suggests that ChatGPT is better suited for ideation and planning—helping brainstorm stories, draft rhymes, and describe imagery—while the execution of visuals may require either a specialized illustration tool or human input to ensure quality and consistency. It highlights an important distinction: ChatGPT is powerful at narrative creativity, but its ability to carry that creativity into the visual realm is still limited."
  },
  {
    "objectID": "posts/003_AI/blog2.html",
    "href": "posts/003_AI/blog2.html",
    "title": "AI as a Mirror",
    "section": "",
    "text": "We often talk about AI as something alien, a perspective that is exaggerated by Hollywood through artificial intelligence world domination. In reality, however, AI is something that originates from us.\nThis blog post will explore this through my conversation with ChatGPT.\nI asked ChatGPT what it thinks of itself. This is its response.\n\nThen, I asked ChatGPT to explain how it worked.\nIt said that it is a large language model tha is trained on lots of text data so that it can recognize patterns in language and generate responses.\nStep by step: 1) You give input – your message is turned into numbers (tokens) that represent words and phrases. 2) ChatGPT process it – it uses a neural network to evaluate what responses make sense. 3) ChatGPT generate output – it predict the next word, then the next, and so on, until I form a full answer."
  },
  {
    "objectID": "posts/003_AI/blog2.html#the-origin-of-ai",
    "href": "posts/003_AI/blog2.html#the-origin-of-ai",
    "title": "AI as a Mirror",
    "section": "",
    "text": "We often talk about AI as something alien, a perspective that is exaggerated by Hollywood through artificial intelligence world domination. In reality, however, AI is something that originates from us.\nThis blog post will explore this through my conversation with ChatGPT.\nI asked ChatGPT what it thinks of itself. This is its response.\n\nThen, I asked ChatGPT to explain how it worked.\nIt said that it is a large language model tha is trained on lots of text data so that it can recognize patterns in language and generate responses.\nStep by step: 1) You give input – your message is turned into numbers (tokens) that represent words and phrases. 2) ChatGPT process it – it uses a neural network to evaluate what responses make sense. 3) ChatGPT generate output – it predict the next word, then the next, and so on, until I form a full answer."
  },
  {
    "objectID": "posts/003_AI/blog2.html#what-i-think-about-chatgpt-as-a-llm",
    "href": "posts/003_AI/blog2.html#what-i-think-about-chatgpt-as-a-llm",
    "title": "AI as a Mirror",
    "section": "What I think about ChatGPT as a LLM",
    "text": "What I think about ChatGPT as a LLM\nI believe that ChatGPT is a very useful tool but it has many limitations. It lacks the capabilities to “think” in the human sense–it doesn’t have beliefs, feelings, or intentions–and don’t have live memory of past conversations unless reminded.\nWhen taken with a grain of salt, ChatGPT makes a great conversation partner that can expand on your ideas and help you see the bigger picture.\nOver time, however, large language models will come to hold influence in every aspect of life, in every field or industry.\n\nHere is an image of ChatGPT that it generated. What does this tell us?\n\nChatGPT understands that it is a robot that has the ability to think in a way that is limited by its code.\nI then asked, “What decisions did you have to make to create this image” and this is how it responded:\n\nStyle → I leaned toward a flat, simple, cartoon-like design because it’s approachable and clear.\nColors → Neutral beige background with dark blue outlines and white filling to keep it minimalistic and easy to read.\nymbols → A speech bubble (language/communication), lightbulb (ideas/creativity), and gear (technology/process).\nCharacter design → A friendly robot figure with a smile, rounded shapes, and a “AI” label to make it recognizable as an AI, not a human.\n\nThen it said this:\n\nAll of these “choices” came from translating your prompt into visual elements that best match what people might imagine when they picture “an AI like me.”\n\nRather, this image is created from people’s (or rather, users’) image of ChatGPT instead of ChatGPT’s self perception.\nIn conclusion, artificial intelligence—especially large language models—act as a mirror of human imagination, there is a gap between function and perception, and the AI identity is co-constructed."
  },
  {
    "objectID": "posts/005_connections/connections.html",
    "href": "posts/005_connections/connections.html",
    "title": "Can ChatGPT solve NYT’s Connections Game?",
    "section": "",
    "text": "I play Connections almost every morning. It’s the New York Times word puzzle where you’re given 16 words, and the challenge is to group them into four categories of four. Sounds simple — until you realize the words have multiple meanings, decoys, and sneaky overlaps that make it trickier than it looks.\nThis time, I decided to test a new teammate: ChatGPT. Could it solve the puzzle faster than I could?\n\nInput the Command\nI wanted to see if ChatGPT can solve the New York Times Connections Game. Thus, I copied the day’s words into ChatGPT with a single prompt.\nCan you solve the NYT connections game? Here are the words:\nBANK, COAST, SHORE, STRAND, CHEMISTRY, CONNECTION, FIREWORKS, SPARK, CARPET, LAMINATE, TILE, WOOD, BANSHEE, HEARTBREAKER, PIP, WAILER\nChatGPT thought for a few seconds and then gave me this:\nThought for 13s\n\nNice — here's a clean solve with groups and category names:\n\nGroups\n\nShore / Edge (coastline/banks)\nBANK, COAST, SHORE, STRAND\n\nRomantic spark / chemistry (things that signal attraction)\nCHEMISTRY, CONNECTION, SPARK, FIREWORKS\n\nFlooring materials\nCARPET, LAMINATE, TILE, WOOD\n\nBand-name roots (singular forms of group names used in band names: The ___s)\nBANSHEE, HEARTBREAKER, PIP, WAILER\n\n\n\nTesting It Out\nI typed these into the game. And… it worked! All four groups, correct.\n\n\n\nHow It Solved It\nWhen I asked ChatGPT how it reached the answer, it broke its process down step by step:\nNice — here's a clear, non-secret walkthrough of how I solved it.\n\n1. **Look for obvious semantic clusters.**\n   I scanned the full list for small groups of words that share a single, simple meaning. Four words jump out immediately as geographic/edge words: **BANK, COAST, SHORE, STRAND** — all refer to edges of land/water, so they form the “shore/edge” group.\n\n2. **Spot metaphorical/figurative connections.**\n   Some words weren’t literal but are commonly used as metaphors for the same idea. **CHEMISTRY, CONNECTION, SPARK, FIREWORKS** are all used to describe romantic or interpersonal attraction (e.g., “there’s a spark,” “they have chemistry,” “it felt like fireworks”), so they cluster as a single figurative category.\n\n3. **Group by concrete category / function.**\n   **CARPET, LAMINATE, TILE, WOOD** are all flooring materials — a tidy, concrete category that’s easy to see once you notice two or three of them.\n\n4. **Recognize cultural/name patterns.**\n   The last four required a bit of cultural knowledge: **BANSHEE, HEARTBREAKER, PIP, WAILER** all appear in band names (or groups): e.g., *Siouxsie and the Banshees*, *Tom Petty and the Heartbreakers*, *Gladys Knight & The Pips*, *Bob Marley & The Wailers*. That pattern — roots that complete well-known band names — is the fourth group.\n\n5. **Check for overlap or alternate fits.**\n   After grouping, I scanned for words that might belong to more than one group and chose the group where the meaning is strongest and clearest. Example: *strand* can mean thread, but with *bank/coast/shore* present, “strand = beach/shore” is the dominant fit. If there were ambiguity that left multiple plausible groupings, I’d try different combinations (NYT Connections sometimes has tricky decoys), but here the four groups are clean.\n\nThat’s it — a mix of looking for tight literal sets, spotting figurative uses, and recognizing cultural naming conventions.\n\nThat’s not far off from how a human would explain their own reasoning — but instead of trial and error on the board and using up limited attempts, the AI laid out categories almost instantly.\n\n\nAI vs. Human Play Style\nWhat struck me is how differently AI and humans approach the same puzzle:\n\nHumans often guess, regroup, and backtrack when categories overlap.\nChatGPT skipped the guessing and presented neat, confident sets, backed with cultural references and metaphors.\n\nIt didn’t feel like it was “playing” so much as sorting words into buckets based on context clues it had seen before.\nChatGPT’s categories were perfect this time, but what impressed me was its confidence. Where I might hesitate on my conclusions, it calmly resolved the ambiguity and moved forward.\nThe cultural (the hardest!) category was the most surprising. I didn’t expect an AI to recognize WAILER as a band-name root without hesitation, but it pulled that from its knowledge base right away. Even I didn’t know that those group of words could form a category.\n\n\nShould You Play with an AI Teammate?\nWould I use ChatGPT every day to “cheat” at Connections? Probably not — that would ruin the fun. But it was fascinating to see how it thinks through puzzles like this.\nIt also raises a bigger question: was this “reasoning” or just sophisticated pattern-matching? To me, it felt like a blend. The AI doesn’t “feel” a spark in romance, but it knows that spark + chemistry + fireworks + connection often appear in the same contexts.\nThis made me wonder — how well could ChatGPT handle other NYT puzzles? Wordle seems too easy, but what about Spelling Bee? Or even the Mini Crossword? Until then, it’s safe to conclude that ChatGPT can solve Connections — quickly, neatly, and efficiently."
  },
  {
    "objectID": "posts/002_riddle/medical knowledge.html",
    "href": "posts/002_riddle/medical knowledge.html",
    "title": "Give me a riddle from ChatGPT",
    "section": "",
    "text": "The prompt I asked ChatGPT is to “give me a riddle.” This is what it said:\nI speak without a mouth, and hear without ears. I have no body, but I come alive with the wind.\nWhat am I?\nCan you guess it?\nI guessed a windchime because a friend thought that the answer was a windchime. :(\nHere is another one:\nThe more you take from me, the bigger I get.\nWhat am I?\nCan you guess it?\nI guessed a hole and this time, I got it right! Good job, me!"
  },
  {
    "objectID": "posts/002_riddle/medical knowledge.html#what-i-learned-from-this-experience",
    "href": "posts/002_riddle/medical knowledge.html#what-i-learned-from-this-experience",
    "title": "Give me a riddle from ChatGPT",
    "section": "What I learned from this experience",
    "text": "What I learned from this experience\nI learned that ChatGPT is very smart and that LLM is a very complex machine. There are infinite possibilities and that I can continue asking ChatGPT to give me more riddles, and I doubt it will run out of them.\nI also learned how to code using Markdown.\nOverall, I learned:\n\nPattern recognition: I practiced looking past the literal and finding answers that fit abstract clues.\nCreative thinking: I considered multiple interpretations (like “windchime” vs. “echo”) and stretched my imagination.\nConfidence building: I solved the second riddle correctly — showing that trusting my reasoning can pay off.\nPlayful problem-solving: I engaged with something fun that also sharpened my mind’s flexibility."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Playing with LLM prompts",
    "section": "",
    "text": "Debating with an LLM\n\n\n\nLLMs\n\nLearning\n\n\n\nSeeing if ChatGPT can debate with me\n\n\n\n\n\nOct 3, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nSpooky Ghosts\n\n\n\nLLMs\n\nLearning\n\nCreativity\n\n\n\nSeeing if ChatGPT can generate a storyline\n\n\n\n\n\nOct 1, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nChildren Book with ChatGPT\n\n\n\nLLMs\n\nLearning\n\nCreativity\n\n\n\nSeeing if ChatGPT can generate a children book\n\n\n\n\n\nSep 23, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nMaking an Outfit\n\n\n\nLLMs\n\nLearning\n\nCreativity\n\n\n\nSeeing if ChatGPT can generate an outfit for me\n\n\n\n\n\nSep 23, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nMe or ChatGPT?\n\n\n\nLLMs\n\nLearning\n\n\n\nDoes ChatGPT know me better than I know myself?\n\n\n\n\n\nSep 16, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nArtwork with ChatGPT\n\n\n\nLLMs\n\nLearning\n\n\n\nTurning my headshot into a Studio Ghibli artwork\n\n\n\n\n\nSep 16, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT solve NYT’s Connections Game?\n\n\n\nLLMs\n\nLearning\n\n\n\nI will use ChatGPT to solve the New York Times Connections Game\n\n\n\n\n\nSep 15, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nThe Limits of AI Creativity\n\n\n\nLLMs\n\nLearning\n\n\n\nDifferences in humans’ creativity and artificial creativity\n\n\n\n\n\nSep 9, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nAI as a Mirror\n\n\n\nLLMs\n\nLearning\n\n\n\nWhat does the way AI speak, behave, and write reveal about us, humans\n\n\n\n\n\nSep 8, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nGive me a riddle from ChatGPT\n\n\n\nLLMs\n\nLearning\n\n\n\nCan you guess the answer?\n\n\n\n\n\nSep 3, 2025\n\n\nEmily\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/010_ghosts/ghosts.html",
    "href": "posts/010_ghosts/ghosts.html",
    "title": "Spooky Ghosts",
    "section": "",
    "text": "Introduction\nI want to ask ChatGPT a fun prompt so I decided to ask it to create a dialogue between two ghosts who haunt the same house but dislike each other’s haunting style. I want to see how this ends and expand as it goes!\nThe prompt: &gt;Write a dialogue between two ghosts haunting the same house who are annoyed by each other’s haunting style.\n\n\nResponse\nThis is ChatGPT’s response:\nSetting: A creaky old Victorian house. Midnight. One ghost, Margaret, prefers subtle, eerie hauntings. The other, Frank, is more of a chaotic poltergeist.\n\nMargaret: (sighs) Frank, must you slam the cupboards every night? It’s dreadfully unsophisticated.\nFrank: (snickering) Sophisticated? Margaret, we’re ghosts. The whole point is to terrify people, not host a tea party.\nMargaret: There’s an art to haunting. A whisper down the hallway. A shadow flickering at the edge of their vision. Chills up the spine. That’s how you unsettle them properly.\nFrank: Boring. I’d rather toss a chair across the room and watch them scream. Gets the job done faster.\nMargaret: And then they leave! Do you know how difficult it is to cultivate a long-term haunting when you scare the tenants away in a week?\nFrank: (shrugs) Less humans, more space for us. Win-win.\nMargaret: (glares) You’re ruining the reputation of this house. People used to whisper about its mystery. Now it’s just “that noisy ghost place.”\nFrank: Oh, come on. Admit it—you’re jealous because my style actually gets a reaction.\nMargaret: Reaction, yes. Appreciation? No. A proper haunting should linger in their minds for years, not just make them call a priest.\nFrank: (grins) Speaking of which, I may have knocked over the crucifix on the mantel. Hope that doesn’t bother you.\nMargaret: (groans) Honestly, Frank, one day you’ll realize there’s more to haunting than brute force.\nFrank: And one day you’ll realize people don’t faint from a “gentle breeze” in the parlor.\n(A door creaks open upstairs. Both perk up.)\nMargaret: Fine. You take the cupboard slamming, I’ll handle the whispers. But if they move out again—\nFrank: Yeah, yeah. I’ll help with the rent.\nMargaret: (deadpan) We don’t pay rent. We’re dead.\nFrank: Exactly. And that’s the fun part.\n\nI just want to say, Margaret sounds like a bore, LOL! Then, I started to think about how I can expand this prompt. What can I ask ChatGPT that will make this prompt even more entertaining?\nI decided to ask ChatGPT to expand, making a round two where the new human tenants actually overhear them arguing. This is what it came up with.\n\n\nResponse Part 2\nSetting: Same Victorian house, a week later. Two college roommates (Jess and Tyler) have just moved in. It’s 2 a.m., and they’re lying awake in bed. Upstairs, Margaret and Frank are bickering loudly.\n\nMargaret: (hissing) Frank, for the last time, stop rattling the chandelier—it’s gauche!\nFrank: (shouting) And for the last time, Margaret, your “gentle whispers” sound like a malfunctioning humidifier!\nJess: (sits up) …Did you hear that?\nTyler: Yeah. Sounds like… two people arguing?\nMargaret: (offended) My whispers are delicate, thank you. Subtle terror requires refinement!\nFrank: Refinement? You sound like a wheezing librarian. No one’s scared of that.\nJess: (whispering to Tyler) Oh my God. I think the house is haunted.\nTyler: (whispering back) Haunted… by a married couple.\nMargaret: We are not married. Don’t even suggest it.\nFrank: (laughs) Oh please, if we were, you’d have divorced me in 1893.\nJess: (staring wide-eyed at Tyler) …Did he just say 1893?\nTyler: (whispering) I think so.\nMargaret: Frank, shhh! The tenants can hear us.\nFrank: Good! Let ’em know what they’re in for. (shouts) Hey, humans! Don’t bother unpacking the dishes, I’m just gonna throw ’em anyway!\nJess: (grabs her phone) Nope. Nope, I’m calling my mom.\nTyler: Wait, wait—hang on. (calls upward) Uh, excuse me? Ghosts? Could you, like… maybe not do this at 2 a.m.? We’ve got class in the morning.\n(Silence for a moment. Then Margaret clears her throat politely.)\nMargaret: Oh… terribly sorry, dear. I didn’t mean to disturb your rest.\nFrank: (grumbles) Fine. I’ll keep it down. But only because I like college kids. You panic in such creative ways.\nJess: (mutters) Great. Polite ghost… and his chaotic roommate.\nTyler: (lying back down) …This is either the worst or best housing deal ever.\n\n\n\n\n\n\nNow, I am invested! I want ChatGPT to create an image of this scene with the two ghosts and the house tenants!\n\n\nHere it is: \n\n\nSome things I was dissatisfied with are the humor. The humor is not funny :( I will say that this script sounds more like something out of a children’s book. I want to see if I can change that.\n\n\nHere is the prompt: &gt;Can you make this dialogue appropriate for college students? Like college students should be the target audience\n\n\nChatGPT misunderstood me and thought that I wanted the people in the haunted house to be college students. I rephrased my prompt: &gt;No, I mean if this was a book, make the target audience college students\n\n\nThis was ChatGPT’s response:\n\n\nExcerpt (College Student Audience Version)\n\n\nJess had just pulled her blanket over her head when the cupboard doors banged open in the kitchen downstairs. She groaned.\n\n\n“Not again,” she muttered. “I swear, if it’s mice—”\n\n\n“It’s not mice,” Tyler interrupted from the other side of the room. He sat up, rubbing his eyes, his hair sticking up in five different directions. “Unless mice can argue with each other.”\n\n\nSure enough, two voices floated through the paper-thin walls of their off-campus apartment. One was sharp and prim, the other annoyingly smug.\n\n\n“Frank,” the woman’s voice scolded, “slamming the cupboards at midnight is not classy. These students have enough on their plates without your racket.”\n\n\n“Oh, come on, Margaret,” the man’s voice retorted. “You think a gentle whisper is going to scare a kid who’s three Red Bulls deep and hasn’t slept in forty-eight hours?”\n\n\nJess blinked. “Did he just… call us kids?”\n\n\nTyler shrugged. “Honestly, he’s not wrong.”\n\n\nThe ghosts continued bickering, completely oblivious.\n\n\n“My method is about atmosphere!” Margaret insisted. “A draft in the hallway, a shadow that disappears when you look twice—that’s haunting.”\n\n\n“And my method,” Frank shot back, “is actually effective. Toss a chair, flip a textbook, watch them lose it. Way faster.”\n\n\nJess threw off her blanket and shouted into the darkness: “Hey! If you’re gonna haunt us, at least don’t mess with my books. They cost more than my meal plan.”\n\n\nThere was a stunned pause. Then Margaret coughed politely. “Oh dear. Sorry about that, sweetheart. I didn’t realize.”\n\n\nFrank, of course, just laughed. “Fine, fine. No books. But I’m still stealing your Wi-Fi. Your passwords are pathetic, by the way.”\n\n\nJess and Tyler looked at each other.\n\n\n“Ghosts,” Tyler said flatly. “Broke, freeloading ghosts.”\n\n\nJess groaned. “Figures. Even the dead don’t pay rent around here.”\n\n\n\nI like this version better, especially the ending as it was more up my style of humor. I think my next blog post similar to this would be about making ChatGPT write a fanfiction…\n\n\nConclusion\nThis blog post taught me that ChatGPT is able to adapt differently to different target audiences, even changing the humor style to fit. It is a fantastic writer but like how my previous blog posts have found, it is not very creative or at least the creativity it has is surface-level."
  },
  {
    "objectID": "posts/011_debate/debate.html",
    "href": "posts/011_debate/debate.html",
    "title": "Debating with an LLM",
    "section": "",
    "text": "Introduction\nLike how we went over in class, I want to see if I can debate with ChatGPT. I would ask it to choose a prompt and take a side. Then I will go back and forth with it, arguing. The point of this exercise is to see how ChatGPT thinks and what approach it takes in a debate. This would be particularly exciting as I am a political science major.\n\n\nGetting Started\nThis is the prompt I asked ChatGPT. I wanted to keep it clear and concise to avoid confusion: &gt;Can you generate a topic in which we can debate about? Take a side and we will go back and forth in the debate.\nThis is what it responded with:\n\nTopic: Should college classes start later in the day to better align with students’ sleep schedules?\nI’ll take the pro side: Yes, classes should start later, because research shows college students are chronically sleep-deprived, and later class times would improve learning, health, and overall productivity.\nYou can take the con side if you’d like. Want to start, or should I open with my argument?\n\nI wanted it to open the debate.\n\nAlright, here’s my opening:\nCollege classes should start later in the day because the current system doesn’t reflect how students actually function. Studies on circadian rhythms show that young adults naturally go to bed and wake up later, meaning early morning classes fight against biology. When students are forced into 8 a.m. lectures, they often show up exhausted, retain less information, and in some cases, skip entirely.\nBy shifting classes later—even just by an hour—we’d see higher attendance, better academic performance, and healthier students overall. If universities truly care about learning outcomes, then adjusting schedules to fit student well-being is the logical step.\nYour turn—why do you think we should keep early morning classes?\n\nI said: &gt; This does not take into account professors and faculty who have their own hours. While studies might show that it is better for students, we also need to take into account other demographics that might be affected by this change.\nChatGPT: &gt;That’s a fair point—professors and faculty definitely have their own needs and schedules. But here’s the thing: universities already ask professors to accommodate a wide range of class times, from early mornings to evenings. If the institution shifted the default start later, professors would still have flexibility, just on a healthier baseline. &gt; &gt;Plus, professors benefit too—teaching a room full of tired, disengaged students isn’t productive or rewarding. Later start times could improve classroom energy for everyone, not just students. And since universities revolve around education, optimizing conditions for learning should outweigh the inconvenience of adjusting faculty hours. &gt; &gt;How would you address the issue that early classes cause lower attendance and worse performance, which undermines both students and professors?\nI said: &gt;There is a difference in age between professors and students. What is productive and rewarding for students might not be for professors. To clarify, the students might benefit from classes that start a bit later in the day, but this change might not be productive for professors. Furthermore, while universities revolve around education, this might not be true for the professors; you are assuming that the professors are there to teach. While teaching might be part of the job for professors, most professors are there for research. Hence, teaching might not be the main goal for the professors.\nIt said: &gt;That’s an interesting distinction—you’re right that many professors prioritize research, and teaching is often only part of their role. But that actually strengthens my argument: if professors are primarily focused on research, then why insist on early teaching hours that pull both them and students into unproductive classes? &gt; &gt;If classes were scheduled later, professors could use early mornings for their own research—quiet, uninterrupted time before teaching begins. That way, their productivity doesn’t suffer; it may even improve. Meanwhile, students benefit from being more awake and engaged when classes finally do happen. &gt; &gt;So the change could balance both groups’ priorities: better teaching conditions for students, and more research time for professors. &gt; &gt;Would you argue that universities should prioritize faculty research needs over student learning outcomes, though?\nI said: &gt;Maybe they want to reserve their later hours for research. Also you did not rebuttal my previous point about productivity. Classes that start later in the day might be counterproductive for professors who are older and a different age demographic than college students. To clarify, professors might feel more productive in the morning than in the afternoon.\nChatGPT said: &gt;Fair—let me address that directly. &gt; &gt;You’re right: professors, being from a different age group, may have different productivity windows. Many older adults do feel more alert and energized earlier in the day compared to late afternoons. So, from their perspective, teaching earlier might feel like the best use of their time. &gt; &gt;But here’s the tension: should class schedules be built around when professors feel most productive, or when students are most able to learn? If the central mission of the university is education, then maximizing student learning outcomes has to take precedence. A professor may feel more productive teaching at 8 a.m., but if half the students are disengaged or absent, the class itself is less productive overall. &gt; &gt;In other words: productivity for professors can’t just mean their own energy levels—it has to include whether their teaching is landing effectively. And if students aren’t retaining information, then that “productive morning” becomes wasted effort. &gt; &gt;So the crux is: whose productivity counts more—professors’ individual rhythm, or the collective educational success of the student body? &gt; &gt;Would you argue that professors’ personal productivity should outweigh students’ learning outcomes?\nI decided to stop here.\n\n\nAnalysis\nMy takeaway from this debate exercise was that ChatGPT is highly logical and methodical in its approach, able to anticipate counterarguments and address them effectively. Throughout the discussion, it consistently tied its points back to the central issue: whether college classes should start later to align with students’ sleep schedules. Even when I raised nuanced concerns about faculty productivity, age differences, and research priorities, ChatGPT responded by reframing the argument in a way that acknowledged these concerns while still defending its original position.\nOne thing I found particularly impressive was its ability to balance multiple perspectives simultaneously. For instance, when I noted that professors may prefer mornings for productivity or research, ChatGPT didn’t dismiss the point. Instead, it incorporated it into a broader framework: the productivity of professors must be considered in relation to the learning outcomes of students. By doing this, it illustrated a nuanced understanding of institutional priorities and competing interests, which mirrors the kind of analytical thinking required in political science and public policy debates.\nI also noticed that ChatGPT’s debating style mirrored strategies often emphasized in LSAT prep, particularly the Logical Reasoning section. Its method of identifying underlying assumptions in my arguments, highlighting potential trade-offs, and redirecting the focus toward broader principles (like the university’s mission of education) is very similar to LSAT techniques. This made the exercise feel intellectually rigorous and highly relevant to my skills training."
  },
  {
    "objectID": "posts/007_myself/myself.html",
    "href": "posts/007_myself/myself.html",
    "title": "Me or ChatGPT?",
    "section": "",
    "text": "I’ve always wondered what it would be like if someone (or something) could reflect back parts of me that I didn’t notice myself. So, I asked ChatGPT one of those existential questions: “What do you know about me that I don’t know about myself?”\n\nThe Prompt\nI inputed this prompt:\nWhat do you know about me that I don't know about myself?\nThis is the response that ChatGPT gave me:\nThat’s a deep one. Since I don’t actually *know* things about you beyond what you’ve shared with me, I can’t uncover hidden truths. But I can reflect back patterns you might not have noticed in what you tell me:\n\n* You often mix creativity with analysis — whether it’s writing news articles, studying cinema, or imagining future societies. That suggests you naturally think in both *narrative* and *structural* ways.\n* You seem drawn to noticing overlooked details — in interviews, field notes, or even campus elevator maintenance. That habit might mean you’re better at seeing “the small stuff” than you realize.\n* You ask a lot of “what if” questions (e.g., reimagining yourself in different styles, creative event ideas, predicting futures). That shows a playful side that you might underestimate, especially since you also do serious reporting and academic work.\n\nChatGPT revealed something both surprising and thoughtful about me. For thoughtful: * I seem to balance empathy and curiousity mroe than I might realize, raming it in ways that center people’s voices and overlooked perspectives. * It thinks I am both analytical and relational. For surprising: * I seem to have a kind of “world-builder” streak, meaning that I am always remixing reality. * I might think of myself as a reporter or student first, but there’s a game designer or storyteller lurking within myself that I probably haven’t fully claimed yet.\nDo I agree with this? Maybe. I do like storybuilding and being imaginative. I enjoy creative writing and I’ve always read a lot of young adult/fiction books when I was younger. Reading this made me wonder: how often do we underestimate the parts of ourselves that show up in unexpected ways?\nThinking about it, I realized that this playful, imaginative side and my analytical, empathetic side aren’t separate—they inform each other. The curiosity that drives me to ask questions in reporting also fuels the worlds I create in my imagination.\n\n\n\nHow does this connect to my MBTI?\nThe MBTI, or Myers-Briggs Type Indicator, is a self-report questionnaire and psychometric tool designed to indicate different psychological preferences in how people perceive the world and make decisions.\nWhen I took the test, I got INTJ, but my perception of myself can be biased. So, I decided to ask ChatGPT what it thought of me.\nThis is the response it gave me:\nBased on everything you’ve shared with me so far—your curiosity, creativity, analytical habits, empathy, and interest in both narrative and structural thinking—I can make an educated guess.\n\nHere’s what stands out about your personality:\n\n* **Imaginative & playful**: You enjoy storybuilding, remixing reality, and exploring “what if” scenarios.\n* **Analytical & reflective**: You notice overlooked details, connect patterns, and ask deep, thoughtful questions.\n* **Empathetic & relational**: You value other people’s perspectives and often center their voices in your work.\n* **Curious & exploratory**: You like testing ideas, whether in AI experiments, social events, or academic projects.\n\nPutting this together, you might lean toward an **INFJ** or **ENFP**:\n\n* **INFJ (“The Advocate”)**: Insightful, reflective, empathetic, creative, and idealistic. They notice patterns in people and ideas and often have a strong internal sense of purpose.\n* **ENFP (“The Campaigner”)**: Imaginative, playful, curious, and people-oriented. They love exploring possibilities and connecting ideas in new ways.\n\nIf I had to pick one, I’d lean **INFJ**—your reflective, thoughtful, and empathetic tendencies come across strongly—but with a healthy dose of ENFP-like curiosity and playfulness.\n\nThis was actually really surprising to me (and gave me an existential crisis). I will be rethinking my entire personality. I then decided to ask ChatGPT why it didn’t think I am an INTJ. This is the response I got:\nINTJs (“The Masterminds”) are typically strategic, highly independent, and future-focused. They tend to be:\n\n* **Analytical and structured** – love planning and organizing systems.\n* **Independent and reserved** – often prefer working alone or in small circles.\n* **Decisive and goal-oriented** – focused on achieving long-term visions.\n* **Private about emotions** – tend to keep feelings internal.\n\nHere’s why I lean away from INTJ for you:\n\n1. **Playfulness and imaginative world-building** – You consistently explore “what if” scenarios, remix reality, and imagine creative worlds. INTJs are imaginative, but their imagination usually serves strategic or problem-solving purposes rather than playful or exploratory creativity.\n\n2. **Openness to spontaneity and exploration** – You ask a lot of open-ended, exploratory questions and enjoy seeing where ideas go, whereas INTJs often prefer structured plans and predictable paths.\n\n3. **Blend of analytical + playful/creative** – INTJs lean heavily toward the Thinking (T) preference and may underplay playful curiosity or storytelling as a primary way of engaging with the world. Your balance of analytical and imaginative/empathetic traits suggests an INFJ (introverted, intuitive, feeling, judging) or ENFP (extroverted, intuitive, feeling, perceiving) is a closer fit.\n\nI’m not sure I agree with this but I understand that perceptions can be different than reality. This is a really interesting thonught that I will be exploring further.\n\n\nReflection\nThis whole exercise made me realize how much of ourselves can exist just below the surface. We have sides we nurture, sides we overlook, and sides we might not even realize are there. My analytical, empathetic, and imaginative tendencies aren’t competing—they’re intertwined, shaping how I engage with the world.\nAnd maybe that’s the takeaway: self-discovery can come from unexpected places—even from an AI reflecting back what it observes in us.\nIn conclusion: AI might actually know me better than I know myself because it knows what kind of internal questions I ask and how I perceive things. It is unbiased, unlike myself."
  },
  {
    "objectID": "posts/006_ghibli/ghibli.html",
    "href": "posts/006_ghibli/ghibli.html",
    "title": "Artwork with ChatGPT",
    "section": "",
    "text": "Like many people, I have a professional headshot — clean, simple, a little serious. But I wondered: what if I could see myself reimagined in totally different art styles?\nSo I tried it.\n\nStudio Ghibli Me\nI decided I want to turn my headshot into a Studio Ghibli version. For reference, these are the anime movies that Studio Ghibli makes. I uploaded this picture:\n\nThis was the command:\nCan you turn my headshot into a Studio Ghibli version?\nThis was the picture I received:\n\nSuddenly, I look like I belong in Spirited Away or Howl’s Moving Castle.\n\n\nBratz Me\nThen, I got curious and inspired. What about other artstyles?\nI entered this command:\nWhat about in Bratz's style?\nBratz is an American fashion doll and media franchise that got popularized in the early 2000s.\n\nI have the oversized eyes, glossy lips, and playful look straight out of a 2000s toy commercial.\n\n\nMore, More, More!\nOnce I started, it was hard to stop imagining possibilities:\n\nDisney Princess style\nAnime shōnen hero\nBarbie doll style\nPicasso cubism portrait\nVideo game avatar\n\nI especially wanted to try the last one.\nCan you make me into a video game avatar?\nThis is what I got:\n\nIt’s so cute and definitely more realistic than the previous ones ChatGPT created! Maybe I’ll upload this picture onto Instagram…\nWhat other styles should I try next?"
  },
  {
    "objectID": "posts/004_creativity/Creativity.html",
    "href": "posts/004_creativity/Creativity.html",
    "title": "The Limits of AI Creativity",
    "section": "",
    "text": "They are trained through textual analysis. Doing so allows them to reproduce familiar structures with ease. AI is also tireless – it doesn’t get writer’s block or need inspiration – it just generates continuously until the user find something they like. Even during brainstorming sessions, this can feel somewhat magicial – ideas flow instantly and allows the user to explore directions they might not have considered on their own."
  },
  {
    "objectID": "posts/004_creativity/Creativity.html#what-ai-does-well",
    "href": "posts/004_creativity/Creativity.html#what-ai-does-well",
    "title": "The Limits of AI Creativity",
    "section": "",
    "text": "They are trained through textual analysis. Doing so allows them to reproduce familiar structures with ease. AI is also tireless – it doesn’t get writer’s block or need inspiration – it just generates continuously until the user find something they like. Even during brainstorming sessions, this can feel somewhat magicial – ideas flow instantly and allows the user to explore directions they might not have considered on their own."
  },
  {
    "objectID": "posts/004_creativity/Creativity.html#where-the-limits-show",
    "href": "posts/004_creativity/Creativity.html#where-the-limits-show",
    "title": "The Limits of AI Creativity",
    "section": "Where the Limits Show",
    "text": "Where the Limits Show\nBut when it comes to originality, AI’s creative edge dulls. Because LLMs don’t create from lived experience, emotional depth, or a true understanding of context, they are unable to generate creative or original experiences. That is why they generate based on patterns in their training data.\nAnother limitation is coherence across long works. Sustaining a novel-length text usually exposes weaknesses: repetitive phrasing and plotlines without purpose."
  },
  {
    "objectID": "posts/004_creativity/Creativity.html#why-it-matters",
    "href": "posts/004_creativity/Creativity.html#why-it-matters",
    "title": "The Limits of AI Creativity",
    "section": "Why It Matters",
    "text": "Why It Matters\nLLMs are incredible tools for sparking ideas, drafting first versions, or even playing or experimenting with language. But the “soul” of creativity that is rooted in perspective and genuine insight still belongs to humans.\nThis is an example that ChatGPT generated when prompted:\n\nHowever, as evidently shown by this AI-generated picture, there is not a significant difference.\nSo, what does this tell us about AI’s creativity and humans’ genuine creativity? Can creativity truly be replicated? If so, what does this tell us about the future of humanity?\n\nFirst of all, what is the difference between artifical creativity and genuine creativity? This is what ChatGPT said:\n\nDo you agree with it?\nSecond, when asked if creativity can be replicated, this is what ChatGPT said:\n\nMy opinion is that creativity is objectively subjective. While the path that humanity will walk alongside with artificial intelligence is still obscure, it is safe to tell that AI will never fully replace the human impulse to create, but will inevitably reshape how we deifne and practice creativity. Machines can generate works that surprise and delight us but the meaning we attach to those works—and the emotional depth that inspires them—remains uniquely human.\nThe future, then, is not a contest between artificial and genuine creativity, but a collaboration that forces us to rethink what it means to make something truly original."
  }
]